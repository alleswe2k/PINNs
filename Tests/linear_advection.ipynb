{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA\n"
     ]
    }
   ],
   "source": [
    "# CUDA support\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"CUDA\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super(DNN, self).__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        for i in range(len(layers) - 1):\n",
    "            self.layers.append(nn.Linear(layers[i], layers[i+1]))\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers[:-1]:\n",
    "            x = self.activation(layer(x))\n",
    "        return self.layers[-1](x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PINN():\n",
    "    def __init__(self, X, u, layers, bc):\n",
    "\n",
    "        # data \n",
    "        self.x = torch.tensor(X[:, 0:1], requires_grad=True).float().to(device)\n",
    "        self.y = torch.tensor(X[:, 1:2], requires_grad=True).float().to(device)\n",
    "        self.t = torch.tensor(X[:, 2:3], requires_grad=True).float().to(device)\n",
    "        self.u = torch.tensor(u).float().to(device)\n",
    "\n",
    "        # deep neural network\n",
    "        self.dnn = DNN(layers).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.61335377 0.73647826]\n",
      " [0.43335016 0.55927152]\n",
      " [0.38646157 0.34972872]\n",
      " [0.2134694  0.61888963]\n",
      " [0.88979568 0.06257367]\n",
      " [0.12809482 0.29591974]\n",
      " [0.01043387 0.40001404]\n",
      " [0.72238477 0.8918563 ]\n",
      " [0.57656917 0.14609642]\n",
      " [0.95804565 0.96061881]]\n",
      "[[ 0.22670754  0.47295653]\n",
      " [-0.13329967  0.11854305]\n",
      " [-0.22707686 -0.30054257]\n",
      " [-0.57306121  0.23777926]\n",
      " [ 0.77959136 -0.87485265]\n",
      " [-0.74381037 -0.40816051]\n",
      " [-0.97913227 -0.19997193]\n",
      " [ 0.44476953  0.78371259]\n",
      " [ 0.15313833 -0.70780715]\n",
      " [ 0.9160913   0.92123762]]\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import qmc\n",
    "\n",
    "sampler = qmc.LatinHypercube(d=2)\n",
    "sample = sampler.random(n=10)\n",
    "print(sample)\n",
    "l_bounds = [-1, -1]\n",
    "u_bounds = [1, 1]\n",
    "new = qmc.scale(sample, l_bounds, u_bounds)\n",
    "print(new)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pinn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
