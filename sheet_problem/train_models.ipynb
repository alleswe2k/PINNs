{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62934d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pyDOE import lhs\n",
    "\n",
    "import pandas as pd\n",
    "import meshio\n",
    "from torch_geometric.data import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "380aeeea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "NVIDIA GeForce RTX 2060\n"
     ]
    }
   ],
   "source": [
    "# CUDA support\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "print(torch.cuda.get_device_name(torch.cuda.current_device()))  # GPU name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d21db4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super(DNN, self).__init__()\n",
    "        modules = []\n",
    "        for i in range(len(layers) - 2):  # Exclude last layer for activation\n",
    "            modules.append(nn.Linear(layers[i], layers[i+1]))\n",
    "            modules.append(nn.Tanh())\n",
    "        modules.append(nn.Linear(layers[-2], layers[-1]))  # Last layer (no activation)\n",
    "        self.network = nn.Sequential(*modules)\n",
    "\n",
    "        for layer in self.network:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                nn.init.xavier_uniform_(layer.weight)\n",
    "                if layer.bias is not None:\n",
    "                    nn.init.zeros_(layer.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68931d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PINN():\n",
    "    def __init__(self, dnn):\n",
    "\n",
    "        self.track_loss = []\n",
    "\n",
    "        self.w_pde = 1\n",
    "        self.w_bc = 1\n",
    "        self.lr_adam = 0.01\n",
    "        self.lr_lbfgs = 0.005\n",
    "\n",
    "        # DNN\n",
    "        self.dnn = dnn\n",
    "\n",
    "        # Optimizer\n",
    "        self.optimizer_lbfgs = torch.optim.LBFGS(\n",
    "            self.dnn.parameters(),\n",
    "            lr=self.lr_lbfgs,\n",
    "            max_iter=20000,\n",
    "            max_eval=20000,\n",
    "            history_size=200,\n",
    "            tolerance_grad=1e-10,\n",
    "            tolerance_change=1e-10,\n",
    "        )\n",
    "\n",
    "        self.optimizer_adam = torch.optim.Adam(self.dnn.parameters(), lr=self.lr_adam)\n",
    "        self.scheduler = torch.optim.lr_scheduler.StepLR(self.optimizer_adam, step_size=5000, gamma=0.5)\n",
    "        self.iter = 0\n",
    "\n",
    "    def set_var(self, X, Y, masks, h, l, r, nu):\n",
    "        self.x = torch.tensor(X, requires_grad=True).float().to(device).view(-1, 1)\n",
    "        self.y = torch.tensor(Y, requires_grad=True).float().to(device).view(-1, 1)\n",
    "        self.data = torch.cat((self.x, self.y), dim=1)\n",
    "\n",
    "        self.mask_left = masks['left']\n",
    "        self.mask_top = masks['top']\n",
    "        self.mask_right = masks['right']\n",
    "        self.mask_down = masks['down']\n",
    "        self.mask_hole = masks['hole']\n",
    "\n",
    "        self.nu = nu\n",
    "\n",
    "        self.h = h\n",
    "        self.l = l\n",
    "        self.r = r\n",
    "\n",
    "    def model_value(self, data):\n",
    "        out = self.dnn(data)\n",
    "        u = out[:,0:1]\n",
    "        v = out[:,1:2]\n",
    "        sxx = out[:,2:3]\n",
    "        syy = out[:,3:4]\n",
    "        sxy = out[:,4:5]\n",
    "        return u, v, sxx, syy, sxy\n",
    "\n",
    "    def pde_loss(self, u, v, sxx, syy, sxy, data):\n",
    "\n",
    "        du = torch.autograd.grad(u, data, torch.ones_like(u), create_graph=True)[0]\n",
    "        dx_u = du[:, 0:1]\n",
    "        dy_u = du[:, 1:2]\n",
    "\n",
    "        dv = torch.autograd.grad(v, data, torch.ones_like(v), create_graph=True)[0]\n",
    "        dx_v = dv[:, 0:1]\n",
    "        dy_v = dv[:, 1:2]\n",
    "\n",
    "        dx_sxx = torch.autograd.grad(sxx, data, torch.ones_like(sxx), create_graph=True)[0][:, 0:1]\n",
    "        dy_syy = torch.autograd.grad(syy, data, torch.ones_like(syy), create_graph=True)[0][:, 1:2]\n",
    "        dsxy = torch.autograd.grad(sxy, data, torch.ones_like(sxy), create_graph=True)[0]\n",
    "        dx_sxy = dsxy[:, 0:1]\n",
    "        dy_sxy = dsxy[:, 1:2]\n",
    "\n",
    "        term_xx = 1 / (1 - self.nu**2) * (dx_u + self.nu*dy_v)\n",
    "        term_yy = 1 / (1 - self.nu**2) * (dy_v + self.nu*dx_u)\n",
    "        term_xy = 1 / (2*(1 + self.nu)) * (dy_u + dx_v)\n",
    "\n",
    "        r1 = torch.mean(torch.pow((sxx - term_xx), 2))\n",
    "        r2 = torch.mean(torch.pow((syy - term_yy), 2))\n",
    "        r3 = torch.mean(torch.pow((sxy - term_xy), 2))\n",
    "        r4 = torch.mean(torch.pow((dx_sxx + dy_sxy), 2))\n",
    "        r5 = torch.mean(torch.pow((dy_syy + dx_sxy), 2))\n",
    "\n",
    "        residual = r1 + r2+ r3 + r4 + r5\n",
    "        return residual\n",
    "\n",
    "    def bc_loss(self, u, v, sxx, syy, sxy, data):\n",
    "\n",
    "        b = torch.mean(torch.pow(u[self.mask_left], 2))\n",
    "        b += torch.mean(torch.pow(v[self.mask_left], 2))\n",
    "\n",
    "        b += torch.mean(torch.pow(syy[self.mask_top], 2))\n",
    "        b += torch.mean(torch.pow(sxy[self.mask_top], 2))\n",
    "\n",
    "        b += torch.mean(torch.pow(sxx[self.mask_right] - 1, 2))\n",
    "        b += torch.mean(torch.pow(sxy[self.mask_right], 2))\n",
    "\n",
    "        b += torch.mean(torch.pow(syy[self.mask_down], 2))\n",
    "        b += torch.mean(torch.pow(sxy[self.mask_down], 2))\n",
    "\n",
    "        x = data[:, 0:1]\n",
    "        y = data[:, 1:2]\n",
    "        nx = -(x[self.mask_hole]-self.l/2)/self.r\n",
    "        ny = -(y[self.mask_hole]-self.h/2)/self.r\n",
    "        tx = torch.mul(sxx[self.mask_hole], nx) + torch.mul(sxy[self.mask_hole], ny)\n",
    "        ty = torch.mul(sxy[self.mask_hole], nx) + torch.mul(syy[self.mask_hole], ny)\n",
    "\n",
    "        b += torch.mean(torch.pow(tx, 2))\n",
    "        b += torch.mean(torch.pow(ty, 2))\n",
    "\n",
    "        return b\n",
    "\n",
    "    \n",
    "    def loss_func(self):\n",
    "        u, v, sxx, syy, sxy = self.model_value(self.data)\n",
    "        pde = self.pde_loss(u, v, sxx, syy, sxy, self.data)\n",
    "        bc = self.bc_loss(u, v, sxx, syy, sxy, self.data)\n",
    "        return pde, bc\n",
    "\n",
    "\n",
    "    def lbfgs_func(self):\n",
    "        pde_loss, bc_loss = self.loss_func()\n",
    "        loss = self.w_pde*pde_loss + self.w_bc*bc_loss\n",
    "        self.optimizer_lbfgs.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        self.track_loss.append(loss.item())\n",
    "\n",
    "        if self.iter % 100 == 0:\n",
    "            print(f\"Iter: {self.iter}, Loss: {'{:e}'.format(loss.item())}\")\n",
    "        self.iter += 1\n",
    "        return loss\n",
    "    \n",
    "    def train(self, epochs=1000):\n",
    "        self.dnn.train()\n",
    "        for epoch in range(epochs):\n",
    "            pde_loss, bc_loss = self.loss_func()\n",
    "            loss = self.w_pde*pde_loss + self.w_bc*bc_loss\n",
    "\n",
    "            self.optimizer_adam.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer_adam.step()\n",
    "            self.scheduler.step()\n",
    "\n",
    "            self.track_loss.append(loss.item())\n",
    "\n",
    "            if epoch % 100 == 0:\n",
    "                print(f\"Epoch {epoch}, Loss: {'{:e}'.format(loss.item())}\")\n",
    "                print(f\"PDE: {'{:e}'.format(pde_loss.item())}, BC: {'{:e}'.format(bc_loss.item())}\")\n",
    "        self.optimizer_lbfgs.step(self.lbfgs_func)\n",
    "\n",
    "    def predict(self, x, y):\n",
    "        x = torch.tensor(x, dtype=torch.float, device=device).view(-1, 1)\n",
    "        y = torch.tensor(y, dtype=torch.float, device=device).view(-1, 1)\n",
    "        data = torch.cat((x, y), dim=1)\n",
    "\n",
    "        self.dnn.eval()\n",
    "        u, v, sxx, syy, sxy = self.model_value(data)\n",
    "        u = u.detach().cpu().numpy()\n",
    "        v = v.detach().cpu().numpy()\n",
    "        sxx = sxx.detach().cpu().numpy()\n",
    "        syy = syy.detach().cpu().numpy()\n",
    "        sxy = sxy.detach().cpu().numpy()\n",
    "        return u, v, sxx, syy, sxy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pinn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
