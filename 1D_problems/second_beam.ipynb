{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA\n"
     ]
    }
   ],
   "source": [
    "# CUDA support\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"CUDA\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"CPU\")\n",
    "\n",
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super(DNN, self).__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        for i in range(len(layers) - 1):\n",
    "            self.layers.append(nn.Linear(layers[i], layers[i+1]))\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers[:-1]:\n",
    "            x = self.activation(layer(x))\n",
    "        return self.layers[-1](x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E = 1.0\n",
    "I = 1.0\n",
    "F = -1.0\n",
    "L = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PINN():\n",
    "    def __init__(self, X, layers):\n",
    "        \n",
    "        self.x = torch.tensor(X, requires_grad=True).float().to(device)\n",
    "\n",
    "        # DNN\n",
    "        self.dnn = DNN(layers).to(device)\n",
    "\n",
    "        # Optimizer\n",
    "        self.optimizer_lfbgs = torch.optim.LBFGS(\n",
    "            self.dnn.parameters(),\n",
    "            lr=0.1,\n",
    "            max_iter=50000,\n",
    "            max_eval=50000,\n",
    "            history_size=50,\n",
    "            tolerance_grad=1e-7,\n",
    "            tolerance_change=1.0 * np.finfo(float).eps,\n",
    "            line_search_fn=\"strong_wolfe\"\n",
    "        )\n",
    "\n",
    "        self.optimizer_adam = torch.optim.Adam(self.dnn.parameters(), lr=0.01)\n",
    "        self.iter = 0\n",
    "\n",
    "    def model_value(self, x):\n",
    "        u = self.dnn(x)\n",
    "        return u\n",
    "    \n",
    "    def loss_func(self, x):\n",
    "        u = self.model_value(x)\n",
    "        u_x = torch.autograd.grad(u, x, torch.ones_like(u), create_graph=True)[0]\n",
    "        u_2x = torch.autograd.grad(u_x, x, torch.ones_like(u_x), create_graph=True)[0]\n",
    "        u_3x = torch.autograd.grad(u_2x, x, torch.ones_like(u_2x), create_graph=True)[0]\n",
    "        u_4x = torch.autograd.grad(u_3x, x, torch.ones_like(u_3x), create_graph=True)[0]\n",
    "\n",
    "        # BC\n",
    "        bc_loss = torch.mean(u[0]**2)\n",
    "        bc_loss += torch.mean(u_x[0]**2)\n",
    "        bc_loss += torch.mean(u_2x[-1]**2)\n",
    "        bc_loss += torch.mean((E*I*u_3x[-1] + F)**2)        \n",
    "\n",
    "        # PDE\n",
    "        residual = torch.mean((E * I * u_4x)**2)\n",
    "\n",
    "        return residual + bc_loss\n",
    "    \n",
    "    def lbfgs_func(self):\n",
    "        loss = self.loss_func(self.x)\n",
    "\n",
    "        self.optimizer_lfbgs.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        self.iter += 1\n",
    "        if self.iter % 100 == 0:\n",
    "            print(f\"Iter: {self.iter}, Loss: {loss.item():.9f}\")\n",
    "        return loss\n",
    "    \n",
    "    def train(self, epochs=1000):\n",
    "        self.dnn.train()\n",
    "        for epoch in range(epochs):\n",
    "            loss = self.loss_func(self.x)\n",
    "\n",
    "            self.optimizer_adam.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer_adam.step()\n",
    "\n",
    "            if epoch % 500 == 0:\n",
    "                print(f\"Epoch {epoch}, Loss: {loss.item():.9f}\")\n",
    "\n",
    "        self.optimizer_lfbgs.step(self.lbfgs_func)\n",
    "\n",
    "    def predict(self, X):\n",
    "        x = torch.tensor(X, requires_grad=True).float().to(device)\n",
    "\n",
    "        self.dnn.eval()\n",
    "        u = self.model_value(x)\n",
    "        u = u.detach().cpu().numpy()\n",
    "        return u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pinn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
